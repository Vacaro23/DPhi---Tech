# -*- coding: utf-8 -*-
"""Explainable_AI_Shap .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XDg8UaqR7wkD-2jD7ouyOBA5O5RFfshK

### **Overview**

Throughout this assignment, you will be performing specific well-defined tasks that’ll strengthen your concepts in Explainable AI. We will be using the Breast Cancer Dataset and here is a brief context about the same:

Breast cancer is a type of cancer that starts in the breast. Cancer starts when cells begin to grow out of control. Breast cancer cells usually form a tumor that can often be seen on an x-ray or felt as a lump. Breast cancer occurs almost entirely in women, but men can get breast cancer, too.
A benign tumor is a tumor that does not invade its surrounding tissue or spread around the body. A malignant tumor is a tumor that may invade its surrounding tissue or spread around the body.

As part of the assignment, you will have to accomplish the below tasks.

**Author:** Ayoub Berdeddouch

###**Dataset**

Dataset Link: https://raw.githubusercontent.com/dphi-official/Datasets/master/breast_cancer/Training_set_breastcancer.csv

**About the dataset:**

Different features related to the breast are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe the characteristics of the cell nuclei present in the image.


* id: Id number
* agnosis: Cancer is Malignant or Benign (M = malignant, B = benign) - target variable

Other 20 features contain information about following 10 real valued features

* radius (mean of distances from center to points on the perimeter)
* texture (standard deviation of gray-scale values) 
* perimeter 
* area 
* smoothness (local variation in radius lengths) 
* compactness (perimeter^2 / area - 1.0) 
* concavity (severity of concave portions of the contour) 
* concave points (number of concave portions of the contour) 
* symmetry  
* fractal dimension ("coastline approximation" - 1)

# Task 1

## Import Necessary Libraries
"""

pip install shap

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_recall_fscore_support
from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer, f1_score

import shap

#ignoring all warnings
import warnings
warnings.filterwarnings('ignore')

# load JS visualization code to notebook. Without this, the SHAP plots won't be displayed
shap.initjs()

"""## Load the data
Display the first 5 rows of the data after loading.
"""

url = 'https://raw.githubusercontent.com/dphi-official/Datasets/master/breast_cancer/Training_set_breastcancer.csv'
data = pd.read_csv(url)
data.reset_index(drop=True)

og_data = pd.read_csv(url)
og_data.reset_index(drop=True)

data.head(5)

og_data.head()

"""## Perform Basic Exploratory Data Analysis (EDA)"""

data.info()

data.describe()

data.corr()

#Visualize the correlation
plt.figure(figsize=(14,14))  #14in by 14in
sns.heatmap(data.corr(), annot=True, fmt='.0%')

#Print all of the object data types and their unique values
for column in data.columns:
    if data[column].dtype == object:
        print(str(column) + ' : ' + str(data[column].unique()))
        print(data[column].value_counts())
        print("_________________________________________________________________")

sns.countplot(data=data,x="diagnosis")

#Count the empty (NaN, NAN, na) values in each column
data.isna().sum()

cat_cols = data.select_dtypes(['category']).columns # Storing names of all categorical columns in cat_cols
cat_cols

data[cat_cols] = data[cat_cols].apply(lambda x: x.cat.codes) # Converting the categorical columns into numerical columns
data.head()

data["diagnosis"] = data.diagnosis.astype("category").cat.codes


# B == 0 
# M == 1
data.head()

"""## Split the data into Train and Test Sets
The train to test ratio should be 80:20 and the random_state should be 0.
"""

X = data.drop(['diagnosis'], axis = 1)
Y = data['diagnosis']

print(X.shape,Y.shape)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)
print(X_train.shape, X_test.shape)
X_train.head()

X_test.shape

X_og = og_data.drop(['diagnosis'], axis = 1)
Y_og = og_data['diagnosis']

X_train_disp, X_test_disp, y_train_disp, y_test_disp = train_test_split(X_og, Y_og, test_size=0.3, random_state=42)
print(X_train_disp.shape, X_test_disp.shape)
X_train_disp.head(3)

"""# Task 2

## Use Random Forest Machine Learning Model for prediction
"""

# There was an Error during Explainer while using Random Forest, exhausting all resources and still cant' solve
# Use XGB instead

import xgboost as xgb #importing xgboost model from xgb library
xgc = xgb.XGBClassifier(n_estimators=500, max_depth=5, random_state=42) # Creating a XGB Classifier

xgc.fit(X_train, y_train) # Training the model with fit method

predictions = xgc.predict(X_test)
predictions[:10]

accuracy_score(y_test, predictions)

"""## Evaluate the model using Accuracy Score"""

print(classification_report(y_test, predictions, target_names=['B', 'M']))

cm = confusion_matrix(y_test, predictions)
ConfusionMatrixDisplay(confusion_matrix=cm).plot()

"""# Task 3: Explaining the model with SHAP and Lime.

##  Use a SHAP Explainer to derive SHAP Values for the random forest ml model.
"""

# creating an explainer for our model
explainer = shap.TreeExplainer(xgc)

# finding out the shap values using the explainer
shap_values = explainer.shap_values(X_test)

# Expected/Base/Reference value = the value that would be predicted if we didn’t know any features of the current output”
print('Expected Value:', explainer.expected_value)

# displaying the first 5 rows of the shap values table
pd.DataFrame(shap_values).head()

"""## Write your inferences from the generated plot.

Expected Value: -1.1105161 being displayed above will be used as the base value throughout all the visualizations below. The values above this base value will be put into class 1 (malignant) wheras the values below it will be put into class 0 (benign).

# Task 4

## Plot a SHAP force plot for the first row of test data.
"""

y_test_disp[0]

shap.initjs()
shap.force_plot(explainer.expected_value, 
                shap_values[0,:], X_test_disp.iloc[0,:])

"""## Write your inferences from the generated plot.

Features pushing the prediction higher are shown in red, those 
pushing the prediction lower are in blue.

Base/ Expected Value: -1.1105161

We can see most of the features are displayed in RED i.e. these features contributed in making the Diagnosis as BENIGN.

The final value "5.66" is higher than the base value. Hence, Benign.

# Task 5

## Plot a SHAP force plot for all the rows of the data
"""

shap.initjs()
shap.force_plot(explainer.expected_value, 
                shap_values[:1000,:], X_test.iloc[:1000,:])

"""## Write your inferences from the generated plot.

*   First 36 test samples probably have Benign Diagnosis with main features of (1) parameters_worst (2) concave_points_mean, and (3) concave_points_worst
*   36-50 samples test samples probably were Malignant with main driver (1) texture_worst for most
*   50-60 test samples have inclination with same factors on the first 36
*   60 to 110 test samples decline towards to Malignant Diagnosis with three to four main blue features

# Task 6

## Plot a SHAP summary plot using all the features in the data
"""

shap.initjs()
shap.summary_plot(shap_values, 
                  X_test, plot_type="bar")

"""## Write your inferences from the generated plot.

Let's exclude the "id"

*    In this Summarry plot, (1) perimeter_worst, (2) concave points_mean (3) concave points_worst (4) texture_worse and (5) are_se are the top 5 features affective if a Diagnosis are either Benign or Malignant which have seen in Force Plot above.

# Task 7

##Plot a SHAP dependecne plot using all features in the data
"""

shap.initjs()
shap.summary_plot(shap_values, X_test)

"""## Write your inferences from the generated plot.

In the above plot, we have provided all the features in X_test to the Summary Plot. We can also provide some specific features instead.

*    The Top 5 features mentioned above, really impacts both the positive and negative SHAP value in determining the diagnosis. As we seen there are a lot of blue and red colors in both sides.
*    In terms of area (1)area_se, (2)are_worse, (3) are(mean) -- these are leaning more on negative SHAP Value below the base value with low impact on the diagnosis.
*    Seeing the texture_worst, this is the only feature that affects few predictions by a large amount.
"""





# sort the features indexes by their importance in the model
# (sum of SHAP value magnitudes over the validation dataset)
top_inds = np.argsort(-np.sum(np.abs(shap_values), 0))

# make SHAP plots of the three most important features
for i in range(20):
    shap.dependence_plot(top_inds[i], shap_values, X_test)

